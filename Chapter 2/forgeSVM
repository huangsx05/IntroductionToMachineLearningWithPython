import mglearn
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# load dataset
X, y = mglearn.tools.make_handcrafted_dataset()
print(X.shape)
print(y)

# train
svm = SVC(kernel='rbf', C=10, gamma=0.1).fit(X, y) #Gaussian Kernel
# plot decision boundary
mglearn.plots.plot_2d_separator(svm, X, eps=.5)
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
# plot support vectors（决定decision boundary的数据点)
sv = svm.support_vectors_
# class labels of support vectors are given by the sign of the dual coefficients
sv_labels = svm.dual_coef_.ravel() > 0 # > 或者 < 号决定每个类别的点的图形，试一下就知道了
mglearn.discrete_scatter(sv[:, 0], sv[:, 1], sv_labels, s=15, markeredgewidth=3)
plt.xlabel("Feature 0")
plt.ylabel("Feature 1")
plt.show() 

## try play with C and gamma parameters （仅为原理展示，与上面的程序无关）
fig, axes = plt.subplots(3, 3, figsize=(15, 10))
for ax, C in zip(axes, [-1, 0, 3]): # try different C
	for a, gamma in zip(ax, range(-1, 2)): # try different gamma
		mglearn.plots.plot_svm(log_C=C, log_gamma=gamma, ax=a)

axes[0, 0].legend(["class 0", "class 1", "sv class 0", "sv class 1"],
					ncol=4, loc=(.9, 1.2))
plt.show()
