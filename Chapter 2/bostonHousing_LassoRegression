# lasso regression, with L1 regularization

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression #linear regression
from sklearn.linear_model import Ridge #ridge regression L2
from sklearn.linear_model import Lasso #lasso regression L1

### Load Dataset
X, y = mglearn.datasets.load_extended_boston() # y是房价。注意这里是mglearn dataset，上面是sklearn dataset
print("X.shape: {}".format(X.shape))

### split data
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

### train and evaluate (linear regression)
lr = LinearRegression().fit(X_train, y_train)
print("Training set score: {:.2f}".format(lr.score(X_train, y_train)))
print("Test set score: {:.2f}".format(lr.score(X_test, y_test)))

### train 1 and evaluate 1 (ridge regression)
ridge = Ridge().fit(X_train, y_train) # use dafault alpha=1.0
print("Training set score 1: {:.2f}".format(ridge.score(X_train, y_train)))
print("Test set score 1: {:.2f}".format(ridge.score(X_test, y_test)))

### train 2 and evaluate 2 (ridge regression)
ridge10 = Ridge(alpha=10).fit(X_train, y_train) # adjust alpha = 10
print("Training set score 2: {:.2f}".format(ridge10.score(X_train, y_train)))
print("Test set score 2: {:.2f}".format(ridge10.score(X_test, y_test)))

### train and evaluate 3 (ridge regression)
ridge01 = Ridge(alpha=0.1).fit(X_train, y_train) # alpha = 0.1
print("Training set score 3: {:.2f}".format(ridge01.score(X_train, y_train)))
print("Test set score 3: {:.2f}".format(ridge01.score(X_test, y_test)))

### 散点图 - coefficient index vs coefficient magnitude
plt.plot(ridge.coef_, 's', label="Ridge alpha=1")
plt.plot(ridge10.coef_, '^', label="Ridge alpha=10")
plt.plot(ridge01.coef_, 'v', label="Ridge alpha=0.1")
plt.plot(lr.coef_, 'o', label="LinearRegression")
plt.xlabel("Coefficient index") # 对应104个feature的w系数
plt.ylabel("Coefficient magnitude")
plt.hlines(0, 0, len(lr.coef_))
plt.ylim(-25, 25)
plt.legend() # 对应上面的label
plt.show()

## 展示learning curve原理
mglearn.plots.plot_ridge_n_samples()
plt.show()

### train and evaluate (lasso regression)
lasso = Lasso().fit(X_train, y_train) # default alpha = 1.0
print("Training set score (lasso 1): {:.2f}".format(lasso.score(X_train, y_train)))
print("Test set score (lasso 1): {:.2f}".format(lasso.score(X_test, y_test)))
print("Number of features used (lasso 1): {}".format(np.sum(lasso.coef_ != 0)))

### try alpha = 0.01
# we increase the default setting of "max_iter",
# otherwise the model would warn us that we should increase max_iter.
lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)
print("Training set score (lasso 2): {:.2f}".format(lasso001.score(X_train, y_train)))
print("Test set score (lasso 2): {:.2f}".format(lasso001.score(X_test, y_test)))
print("Number of features used (lasso 2): {}".format(np.sum(lasso001.coef_ != 0)))

### try alpha = 0.0001
lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)
print("Training set score (lasso 3): {:.2f}".format(lasso00001.score(X_train, y_train)))
print("Test set score (lasso 3): {:.2f}".format(lasso00001.score(X_test, y_test)))
print("Number of features used (lasso 3): {}".format(np.sum(lasso00001.coef_ != 0)))

### plot and compare w values of different regression methods
plt.plot(lasso.coef_, 's', label="Lasso alpha=1")
plt.plot(lasso001.coef_, '^', label="Lasso alpha=0.01")
plt.plot(lasso00001.coef_, 'v', label="Lasso alpha=0.0001")
plt.plot(ridge01.coef_, 'o', label="Ridge alpha=0.1")
plt.legend(ncol=2, loc=(0, 1.05))
plt.ylim(-25, 25)
plt.xlabel("Coefficient index")
plt.ylabel("Coefficient magnitude")
plt.show()