import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn

### Load Dataset
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()

### Overview the data
print("cancer.keys(): \n{}".format(cancer.keys()))
print("Shape of cancer data: {}".format(cancer.data.shape))
print("Sample counts per class:\n{}".format(
{n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})) # zip(n, v)元组
print("Feature names:\n{}".format(cancer.feature_names))

### Split data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
cancer.data, cancer.target, stratify=cancer.target, random_state=66)
training_accuracy = []
test_accuracy = []

# try n_neighbors from 1 to 10
from sklearn.neighbors import KNeighborsClassifier
neighbors_settings = range(1, 11)

for n_neighbors in neighbors_settings:
	# build the model
	clf = KNeighborsClassifier(n_neighbors=n_neighbors)
	clf.fit(X_train, y_train)
	# record training set accuracy
	training_accuracy.append(clf.score(X_train, y_train))
	# record generalization accuracy
	test_accuracy.append(clf.score(X_test, y_test))

plt.plot(neighbors_settings, training_accuracy, label="training accuracy")
plt.plot(neighbors_settings, test_accuracy, label="test accuracy")
plt.ylabel("Accuracy")
plt.xlabel("n_neighbors")
plt.legend()
plt.show() #根据plot选择K