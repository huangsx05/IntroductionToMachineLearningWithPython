import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

# generate dataset
X, y = mglearn.datasets.make_forge()
print(X.shape)

# compare Logistic regression and Linear SVMs
fig, axes = plt.subplots(1, 2, figsize=(10, 3))
for model, ax in zip([LinearSVC(), LogisticRegression()], axes):
	clf = model.fit(X, y)
	mglearn.plots.plot_2d_separator(clf, X, fill=False, eps=0.5,
	ax=ax, alpha=.7)
	mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)
	ax.set_title("{}".format(clf.__class__.__name__))
	ax.set_xlabel("Feature 0")
	ax.set_ylabel("Feature 1")
axes[0].legend()
plt.show()

# illustrate factor C with Linear SVMs 展示原理
mglearn.plots.plot_linear_svc_regularization()
plt.show()